{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Twitter Sentiment Analysis\n",
        "1. This is a Twitter data Sentiment Analysis Program<br>\n",
        "2. This code is implemented using Deep Learning methods .<br>\n",
        "3. I used <font color=#068DA9>Trax</font>.library for implementation.<br>\n",
        "4. Trax is an end-to-end deep learning library focusing on clear code and speed. It is  <font color=#068DA9>actively used and maintained in the <b>Google Brain team.</b> </font><br>\n",
        "5. <a href=\"https://trax-ml.readthedocs.io/en/latest/notebooks/trax_intro.html\">Trax Documetation</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR0EMjcJnTvv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import trax\n",
        "import trax.fastmath.numpy as np\n",
        "from trax import layers as tl\n",
        "\n",
        "# import Layer from the utils.py file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX72FRXoBekt",
        "outputId": "134ab03e-29a3-4e5a-a7a2-816cc2fd1f69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  getpass.getpass = self._save_getpass\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0LbxGxoEG8q",
        "outputId": "b4e4cd1e-f59d-4534-f107-c9b077214571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of positive tweets: 5000\n",
            "The number of negative tweets: 5000\n",
            "length of train_x 8000\n",
            "length of val_x 2000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "all_positive_tweets,all_negative_tweets=load_tweets()\n",
        "print(f\"The number of positive tweets: {len(all_positive_tweets)}\")\n",
        "print(f\"The number of negative tweets: {len(all_negative_tweets)}\")\n",
        "\n",
        "val_pos=all_positive_tweets[4000:]\n",
        "train_pos=all_positive_tweets[:4000]\n",
        "\n",
        "val_neg=all_negative_tweets[4000:]\n",
        "train_neg=all_negative_tweets[:4000]\n",
        "\n",
        "\n",
        "train_x=train_pos+train_neg\n",
        "val_x=val_pos+val_neg\n",
        "\n",
        "\n",
        "train_y_train=np.append(np.ones((len(train_pos),1)),np.zeros((len(train_neg),1)))\n",
        "val_y=np.append(np.ones((len(val_pos),1)),np.zeros((len(val_neg),1)))\n",
        "\n",
        "print(f\"length of train_x {len(train_x)}\")\n",
        "print(f\"length of val_x {len(val_x)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCbYg8ksEiZi",
        "outputId": "b86a3308-d7e1-49b7-9548-867f95596ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original tweet at training position 0\n",
            "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "Tweet at training position 0 after processing:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"original tweet at training position 0\")\n",
        "print(train_pos[0])\n",
        "\n",
        "print(\"Tweet at training position 0 after processing:\")\n",
        "process_tweet(train_pos[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE4TUkI7GGa8",
        "outputId": "838aff49-c6a0-47b8-c5ea-1816e35892a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  getpass.getpass = self._save_getpass\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words in vocab are 9088\n"
          ]
        }
      ],
      "source": [
        "Vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2}\n",
        "\n",
        "for tweet in train_x:\n",
        "  tokens=process_tweet(tweet)\n",
        "  for token in tokens:\n",
        "    if token not in Vocab:\n",
        "      Vocab[token]=len(Vocab)\n",
        "print(\"Total words in vocab are\",len(Vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Ggag7GHcRr",
        "outputId": "c3f8dc9c-d837-4c7b-be4c-f0d09d8a0d4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  getpass.getpass = self._save_getpass\n"
          ]
        }
      ],
      "source": [
        "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
        "  word_l =process_tweet(tweet)\n",
        "  if verbose:\n",
        "        print(\"List of words from the processed tweet:\")\n",
        "        print(word_l)\n",
        "  tensor_l = []\n",
        "\n",
        "  unk_ID =vocab_dict.get(unk_token)\n",
        "  if verbose:\n",
        "    print(f\"The unique integer ID for the unk_token is {unk_ID}\")\n",
        "\n",
        "  for words in word_l:\n",
        "    word_ID=vocab_dict.get(words,unk_ID)\n",
        "    tensor_l.append(word_ID)\n",
        "  return tensor_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAwcnafuKqiH",
        "outputId": "e998956f-e53a-4083-e74e-12f3678c50fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual tweet is\n",
            " Bro:U wan cut hair anot,ur hair long Liao bo\n",
            "Me:since ord liao,take it easy lor treat as save $ leave it longer :)\n",
            "Bro:LOL Sibei xialan\n",
            "\n",
            "Tensor of tweet:\n",
            " [1064, 136, 478, 2351, 744, 8148, 1122, 744, 53, 2, 2671, 790, 2, 2, 348, 600, 2, 3488, 1016, 596, 4558, 9, 1064, 157, 2, 2]\n"
          ]
        }
      ],
      "source": [
        "print(\"Actual tweet is\\n\", val_pos[0])\n",
        "print(\"\\nTensor of tweet:\\n\", tweet_to_tensor(val_pos[0], vocab_dict=Vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS0wf_AaMon8",
        "outputId": "d32c6398-9345-43b4-c227-41f59fa7f143"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  getpass.getpass = self._save_getpass\n"
          ]
        }
      ],
      "source": [
        "import random as rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztWg105eK-sS"
      },
      "outputs": [],
      "source": [
        "def data_generator(data_pos, data_neg, batch_size, loop, vocab_dict, shuffle=False):\n",
        "    assert batch_size % 2 == 0\n",
        "    n_to_take = batch_size // 2\n",
        "\n",
        "    pos_index = 0\n",
        "    neg_index = 0\n",
        "\n",
        "    len_data_pos = len(data_pos)\n",
        "    len_data_neg = len(data_neg)\n",
        "\n",
        "    pos_index_lines = list(range(len_data_pos))\n",
        "    neg_index_lines = list(range(len_data_neg))\n",
        "\n",
        "    if shuffle:\n",
        "        rnd.shuffle(pos_index_lines)\n",
        "        rnd.shuffle(neg_index_lines)\n",
        "\n",
        "    stop = False\n",
        "\n",
        "    # Loop indefinitely\n",
        "    while not stop:\n",
        "        batch = []\n",
        "        for i in range(n_to_take):\n",
        "          if pos_index >= len_data_pos:\n",
        "              if not loop:\n",
        "                  stop = True;\n",
        "                  break;\n",
        "              pos_index = 0\n",
        "              if shuffle:\n",
        "                  rnd.shuffle(pos_index_lines)\n",
        "          tweet = data_pos[pos_index_lines[pos_index]]\n",
        "          tensor = tweet_to_tensor(tweet, vocab_dict)\n",
        "          batch.append(tensor)\n",
        "          pos_index = pos_index + 1\n",
        "\n",
        "        for i in range(n_to_take):\n",
        "          if neg_index>=len_data_neg:\n",
        "            if not loop:\n",
        "              stop=True\n",
        "              break\n",
        "            neg_index=0\n",
        "            if shuffle:\n",
        "              rnd.shuffle(neg_index_lines)\n",
        "          tweet=data_neg[neg_index_lines[neg_index]]\n",
        "          tensor=tweet_to_tensor(tweet,vocab_dict)\n",
        "          batch.append(tensor)\n",
        "          neg_index=neg_index+1\n",
        "\n",
        "        if stop:\n",
        "          break\n",
        "        pos_index+=n_to_take\n",
        "        neg_index+=n_to_take\n",
        "        max_len = max([len(t) for t in batch])\n",
        "        tensor_pad_l = []\n",
        "\n",
        "        for tensor in batch:\n",
        "          n_pad=max_len-len(tensor)\n",
        "          pad_l=[0]*n_pad\n",
        "          tensor_pad=tensor+pad_l\n",
        "          tensor_pad_l.append(tensor_pad)\n",
        "\n",
        "        inputs=np.array(tensor_pad_l)\n",
        "        target_pos=[1]*n_to_take\n",
        "        target_neg=[0]*n_to_take\n",
        "        target_l=target_pos+target_neg\n",
        "        targets=np.array(target_l)\n",
        "        example_weights = np.ones_like(targets)\n",
        "        yield inputs, targets, example_weights\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARsZQSleSXzQ",
        "outputId": "103c30f0-9d3f-4e16-98ac-6fcfd1c05989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs: [[2005 4450 3200    9    0    0    0    0    0    0    0]\n",
            " [4953  566 2000 1453 5173 3498  141 3498  130  458    9]\n",
            " [3760  109  136  582 2929 3968    0    0    0    0    0]\n",
            " [ 249 3760    0    0    0    0    0    0    0    0    0]]\n",
            "Targets: [1 1 0 0]\n",
            "Example Weights: [1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "rnd.seed(30)\n",
        "\n",
        "# Create the training data generator\n",
        "def train_generator(batch_size, shuffle = False):\n",
        "    return data_generator(train_pos, train_neg, batch_size, True, Vocab, shuffle)\n",
        "\n",
        "# Create the validation data generator\n",
        "def val_generator(batch_size, shuffle = False):\n",
        "    return data_generator(val_pos, val_neg, batch_size, True, Vocab, shuffle)\n",
        "\n",
        "# Create the validation data generator\n",
        "def test_generator(batch_size, shuffle = False):\n",
        "    return data_generator(val_pos, val_neg, batch_size, False, Vocab, shuffle)\n",
        "\n",
        "# Get a batch from the train_generator and inspect.\n",
        "inputs, targets, example_weights = next(train_generator(4, shuffle=True))\n",
        "\n",
        "# this will print a list of 4 tensors padded with zeros\n",
        "print(f'Inputs: {inputs}')\n",
        "print(f'Targets: {targets}')\n",
        "print(f'Example Weights: {example_weights}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgzHymhJScXv",
        "outputId": "dcbf3a3b-b543-42fb-9698-1eb2523ced56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The inputs shape is (4, 14)\n",
            "The targets shape is (4,)\n",
            "The example weights shape is (4,)\n",
            "input tensor: [3 4 5 6 7 8 9 0 0 0 0 0 0 0]; target 1; example weights 1\n",
            "input tensor: [10 11 12 13 14 15 16 17 18 19 20  9 21 22]; target 1; example weights 1\n",
            "input tensor: [5736 2900 3760    0    0    0    0    0    0    0    0    0    0    0]; target 0; example weights 1\n",
            "input tensor: [ 857  255 3651 5737  306 4457  566 1229 2766  327 1201 3760    0    0]; target 0; example weights 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tmp_data_gen = train_generator(batch_size = 4)\n",
        "tmp_inputs, tmp_targets, tmp_example_weights = next(tmp_data_gen)\n",
        "\n",
        "print(f\"The inputs shape is {tmp_inputs.shape}\")\n",
        "print(f\"The targets shape is {tmp_targets.shape}\")\n",
        "print(f\"The example weights shape is {tmp_example_weights.shape}\")\n",
        "\n",
        "for i,t in enumerate(tmp_inputs):\n",
        "    print(f\"input tensor: {t}; target {tmp_targets[i]}; example weights {tmp_example_weights[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwlU2vKad-V4"
      },
      "outputs": [],
      "source": [
        "from trax import fastmath\n",
        "\n",
        "# usinng the numpy module from trax\n",
        "np = fastmath.numpy\n",
        "\n",
        "# using the fastmath.random module from trax\n",
        "random = fastmath.random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "3niaRNCefKa-",
        "outputId": "1130fd1d-b8e6-4bbb-f139-1042d47209cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The random seed generated by random.get_prng\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeviceArray([0, 1], dtype=uint32)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "choose a matrix with 2 rows and 3 columns\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight matrix generated with a normal distribution with mean 0 and stdev of 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeviceArray([[ 0.95730704, -0.9699289 ,  1.0070665 ],\n",
              "             [ 0.3661903 ,  0.1729483 ,  0.29092234]], dtype=float32)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tmp_key = random.get_prng(seed=1)\n",
        "print(\"The random seed generated by random.get_prng\")\n",
        "display(tmp_key)\n",
        "\n",
        "print(\"choose a matrix with 2 rows and 3 columns\")\n",
        "tmp_shape=(2,3)\n",
        "display(tmp_shape)\n",
        "tmp_weight = trax.fastmath.random.normal(key=tmp_key, shape=tmp_shape)\n",
        "\n",
        "print(\"Weight matrix generated with a normal distribution with mean 0 and stdev of 1\")\n",
        "display(tmp_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGyVOxLvkB02",
        "outputId": "d4a2fc5c-deef-4fb6-98db-a27d798e8c78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  getpass.getpass = self._save_getpass\n"
          ]
        }
      ],
      "source": [
        "def classifier(vocab_size=len(Vocab), embedding_dim=256, output_dim=2, mode='train'):\n",
        "  embed_layer=tl.Embedding(vocab_size=vocab_size,d_feature=embedding_dim)\n",
        "  mean_layer=tl.Mean(axis=1)\n",
        "  dense_output_layer=tl.Dense(n_units=output_dim)\n",
        "  log_softmax_layer=tl.LogSoftmax()\n",
        "\n",
        "\n",
        "  model=tl.Serial(\n",
        "      embed_layer,\n",
        "      mean_layer,\n",
        "      dense_output_layer,\n",
        "      log_softmax_layer\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXrgBnxTJ6dD"
      },
      "outputs": [],
      "source": [
        "tmp_model=classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "n5QztVDaMRjE",
        "outputId": "49e56b9c-8b20-4379-db10-1c53fa98f060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'trax.layers.combinators.Serial'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Serial[\n",
              "  Embedding_9088_256\n",
              "  Mean\n",
              "  Dense_2\n",
              "  LogSoftmax\n",
              "]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(type(tmp_model))\n",
        "display(tmp_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga7uhItVMS0V"
      },
      "outputs": [],
      "source": [
        "from trax.supervised import training\n",
        "batch_size=16\n",
        "rnd.seed(271)\n",
        "train_task=training.TrainTask(\n",
        "    labeled_data=train_generator(batch_size=batch_size, shuffle=True),\n",
        "    loss_layer=tl.CrossEntropyLoss(),\n",
        "    optimizer=trax.optimizers.Adam(0.01),\n",
        "     n_steps_per_checkpoint=10,\n",
        ")\n",
        "eval_task=training.EvalTask(\n",
        "    labeled_data=val_generator(batch_size=batch_size, shuffle=True),\n",
        "    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
        ")\n",
        "model = classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_HEsxxPOYR8",
        "outputId": "efaa3422-9bb3-4739-badd-ab3ff34e2012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/model/\n"
          ]
        }
      ],
      "source": [
        "output_dir = '~/model/'\n",
        "output_dir_expand = os.path.expanduser(output_dir)\n",
        "print(output_dir_expand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEUGYythOimS"
      },
      "outputs": [],
      "source": [
        "def train_model(classifier,train_task,eval_task,n_steps,output_dir):\n",
        "  training_loop=training.Loop(\n",
        "      classifier,\n",
        "      train_task,\n",
        "      eval_tasks = eval_task,\n",
        "      output_dir=output_dir\n",
        "  )\n",
        "  training_loop.run(n_steps=n_steps)\n",
        "  return training_loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjwblpeUP9pi",
        "outputId": "5972c0d5-f3ef-422d-ac16-e20da5dc9310"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jax/_src/lib/xla_bridge.py:553: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
            "  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 2327042\n",
            "Step      1: Ran 1 train steps in 1.71 secs\n",
            "Step      1: train CrossEntropyLoss |  0.69223136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
            "  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step      1: eval  CrossEntropyLoss |  0.68210447\n",
            "Step      1: eval          Accuracy |  0.50000000\n",
            "\n",
            "Step     10: Ran 9 train steps in 3.99 secs\n",
            "Step     10: train CrossEntropyLoss |  0.63012367\n",
            "Step     10: eval  CrossEntropyLoss |  0.55799788\n",
            "Step     10: eval          Accuracy |  0.87500000\n",
            "\n",
            "Step     20: Ran 10 train steps in 2.22 secs\n",
            "Step     20: train CrossEntropyLoss |  0.41321626\n",
            "Step     20: eval  CrossEntropyLoss |  0.24554147\n",
            "Step     20: eval          Accuracy |  1.00000000\n",
            "\n",
            "Step     30: Ran 10 train steps in 1.83 secs\n",
            "Step     30: train CrossEntropyLoss |  0.20119026\n",
            "Step     30: eval  CrossEntropyLoss |  0.12441064\n",
            "Step     30: eval          Accuracy |  1.00000000\n",
            "\n",
            "Step     40: Ran 10 train steps in 1.43 secs\n",
            "Step     40: train CrossEntropyLoss |  0.13968445\n",
            "Step     40: eval  CrossEntropyLoss |  0.08694202\n",
            "Step     40: eval          Accuracy |  1.00000000\n",
            "\n",
            "Step     50: Ran 10 train steps in 1.02 secs\n",
            "Step     50: train CrossEntropyLoss |  0.05359090\n",
            "Step     50: eval  CrossEntropyLoss |  0.12313829\n",
            "Step     50: eval          Accuracy |  0.93750000\n",
            "\n",
            "Step     60: Ran 10 train steps in 1.96 secs\n",
            "Step     60: train CrossEntropyLoss |  0.06705290\n",
            "Step     60: eval  CrossEntropyLoss |  0.02446628\n",
            "Step     60: eval          Accuracy |  1.00000000\n",
            "\n",
            "Step     70: Ran 10 train steps in 1.33 secs\n",
            "Step     70: train CrossEntropyLoss |  0.04662935\n",
            "Step     70: eval  CrossEntropyLoss |  0.00654723\n",
            "Step     70: eval          Accuracy |  1.00000000\n",
            "\n",
            "Step     80: Ran 10 train steps in 1.40 secs\n",
            "Step     80: train CrossEntropyLoss |  0.05240879\n",
            "Step     80: eval  CrossEntropyLoss |  0.00286950\n",
            "Step     80: eval          Accuracy |  1.00000000\n",
            "\n",
            "Step     90: Ran 10 train steps in 1.26 secs\n",
            "Step     90: train CrossEntropyLoss |  0.02793055\n",
            "Step     90: eval  CrossEntropyLoss |  0.00073539\n",
            "Step     90: eval          Accuracy |  1.00000000\n",
            "\n",
            "Step    100: Ran 10 train steps in 1.09 secs\n",
            "Step    100: train CrossEntropyLoss |  0.01020776\n",
            "Step    100: eval  CrossEntropyLoss |  0.00007024\n",
            "Step    100: eval          Accuracy |  1.00000000\n"
          ]
        }
      ],
      "source": [
        "training_loop = train_model(model, train_task, eval_task, 100, output_dir_expand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWS8XDB_QAby",
        "outputId": "15bf0bbd-4d70-443a-c87f-00578030436a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The batch is a tuple of length 3 because position 0 contains the tweets, and position 1 contains the targets.\n",
            "The shape of the tweet tensors is (16, 15) (num of examples, length of tweet tensors)\n",
            "The shape of the labels is (16,), which is the batch size.\n",
            "The shape of the example_weights is (16,), which is the same as inputs/targets size.\n"
          ]
        }
      ],
      "source": [
        "tmp_train_generator = train_generator(16)\n",
        "tmp_batch = next(tmp_train_generator)\n",
        "tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch\n",
        "\n",
        "print(f\"The batch is a tuple of length {len(tmp_batch)} because position 0 contains the tweets, and position 1 contains the targets.\")\n",
        "print(f\"The shape of the tweet tensors is {tmp_inputs.shape} (num of examples, length of tweet tensors)\")\n",
        "print(f\"The shape of the labels is {tmp_targets.shape}, which is the batch size.\")\n",
        "print(f\"The shape of the example_weights is {tmp_example_weights.shape}, which is the same as inputs/targets size.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwdgOpVnSPl_",
        "outputId": "1a0a440b-a195-4bc6-babd-4251889cc040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The prediction shape is (16, 2), num of tensor_tweets as rows\n",
            "Column 0 is the probability of a negative sentiment (class 0)\n",
            "Column 1 is the probability of a positive sentiment (class 1)\n",
            "\n",
            "View the prediction array\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeviceArray([[-8.5379219e+00, -1.9598007e-04],\n",
              "             [-9.6788101e+00, -6.2465668e-05],\n",
              "             [-8.7531166e+00, -1.5783310e-04],\n",
              "             [-8.5696316e+00, -1.8978119e-04],\n",
              "             [-6.2401304e+00, -1.9514561e-03],\n",
              "             [-7.9618835e+00, -3.4856796e-04],\n",
              "             [-8.6638069e+00, -1.7261505e-04],\n",
              "             [-5.0924158e+00, -6.1621666e-03],\n",
              "             [-2.3238659e-03, -6.0657158e+00],\n",
              "             [-3.2658577e-03, -5.7258863e+00],\n",
              "             [-3.8337708e-04, -7.8665628e+00],\n",
              "             [-4.7683716e-07, -1.4753685e+01],\n",
              "             [-1.1482954e-02, -4.4726315e+00],\n",
              "             [-1.2810230e-03, -6.6608448e+00],\n",
              "             [-2.4194717e-03, -6.0253959e+00],\n",
              "             [-5.3596497e-04, -7.5315137e+00]], dtype=float32)"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_pred = training_loop.eval_model(tmp_inputs)\n",
        "print(f\"The prediction shape is {tmp_pred.shape}, num of tensor_tweets as rows\")\n",
        "print(\"Column 0 is the probability of a negative sentiment (class 0)\")\n",
        "print(\"Column 1 is the probability of a positive sentiment (class 1)\")\n",
        "print()\n",
        "print(\"View the prediction array\")\n",
        "tmp_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVLp4v3UTR-U",
        "outputId": "e8dbc0a9-b098-4029-9e12-95122ec0b390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neg log prob -8.5379\tPos log prob -0.0002\t is positive? True\t actual 1\n",
            "Neg log prob -9.6788\tPos log prob -0.0001\t is positive? True\t actual 1\n",
            "Neg log prob -8.7531\tPos log prob -0.0002\t is positive? True\t actual 1\n",
            "Neg log prob -8.5696\tPos log prob -0.0002\t is positive? True\t actual 1\n",
            "Neg log prob -6.2401\tPos log prob -0.0020\t is positive? True\t actual 1\n",
            "Neg log prob -7.9619\tPos log prob -0.0003\t is positive? True\t actual 1\n",
            "Neg log prob -8.6638\tPos log prob -0.0002\t is positive? True\t actual 1\n",
            "Neg log prob -5.0924\tPos log prob -0.0062\t is positive? True\t actual 1\n",
            "Neg log prob -0.0023\tPos log prob -6.0657\t is positive? False\t actual 0\n",
            "Neg log prob -0.0033\tPos log prob -5.7259\t is positive? False\t actual 0\n",
            "Neg log prob -0.0004\tPos log prob -7.8666\t is positive? False\t actual 0\n",
            "Neg log prob -0.0000\tPos log prob -14.7537\t is positive? False\t actual 0\n",
            "Neg log prob -0.0115\tPos log prob -4.4726\t is positive? False\t actual 0\n",
            "Neg log prob -0.0013\tPos log prob -6.6608\t is positive? False\t actual 0\n",
            "Neg log prob -0.0024\tPos log prob -6.0254\t is positive? False\t actual 0\n",
            "Neg log prob -0.0005\tPos log prob -7.5315\t is positive? False\t actual 0\n"
          ]
        }
      ],
      "source": [
        "tmp_is_positive = tmp_pred[:,1] > tmp_pred[:,0]\n",
        "for i, p in enumerate(tmp_is_positive):\n",
        "    print(f\"Neg log prob {tmp_pred[i,0]:.4f}\\tPos log prob {tmp_pred[i,1]:.4f}\\t is positive? {p}\\t actual {tmp_targets[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "BZ4Z5orSTkFE"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(preds,y,y_weights):\n",
        "    # here Y_weights are array having shape of (len(y),1)\n",
        "    #Therefore sum is total number of y_weights is total\n",
        "    is_pos =  preds[:, 1] > preds[:, 0]\n",
        "    is_pos_int = is_pos.astype(np.int32)\n",
        "    correct = is_pos_int == y\n",
        "    sum_weights = np.sum(y_weights)\n",
        "    correct_float = correct.astype(np.float32)\n",
        "    weighted_correct_float = correct_float * y_weights\n",
        "    weighted_num_correct = np.sum(weighted_correct_float)\n",
        "    accuracy = weighted_num_correct / sum_weights\n",
        "\n",
        "    return accuracy, weighted_num_correct, sum_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "2uMGPbxo44G3"
      },
      "outputs": [],
      "source": [
        "def test_model(generator, model):\n",
        "\n",
        "    accuracy = 0.\n",
        "    total_num_correct = 0\n",
        "    total_num_pred = 0\n",
        "    for batch in generator:\n",
        "        inputs = batch[0]\n",
        "        targets = batch[1]\n",
        "        example_weight = batch[2]\n",
        "        pred = model(inputs)\n",
        "        batch_accuracy, batch_num_correct, batch_num_pred = compute_accuracy(pred, targets, example_weight)\n",
        "        total_num_correct += batch_num_correct\n",
        "        total_num_pred += batch_num_pred\n",
        "    accuracy = total_num_correct / total_num_pred\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qMdmP_8BbLB",
        "outputId": "01a49785-bd56-4972-cfcd-a704cf22273f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of your model on the validation set is 0.9950\n"
          ]
        }
      ],
      "source": [
        "model = training_loop.eval_model\n",
        "accuracy = test_model(test_generator(16), model)\n",
        "\n",
        "print(f'The accuracy of your model on the validation set is {accuracy:.4f}', )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp8QxcTjBgxo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
